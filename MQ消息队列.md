## MQ消息队列

作用：削峰填谷！同步变异步，减少调用链路。

## 三大场景

### 异步

你说了异步，那我⽤线程，线程池去做不是⼀样的么？

​	减少调用链路。如果用线程池不能达到解耦的目的，并且某个线程流程错误（未try/catch）有可能会影响其他节点。同时也便于扩展，支付成功了，只管处理完自己的流程然后发消息出去，后续有接入的系统只需要订阅消息就可以。

那你的流程⾛完了，你不⽤管别⼈是否成功么？⽐如你下单了积分没加，优惠券没扣怎么办？

​	这就是属于分布式事务范畴的问题。

### 削峰

​	

### 解耦

## 三大问题

系统复杂性

​	本来蛮简单的⼀个系统，我代码随便写都没事，现在你凭空接⼊⼀个中间件在那，我是不是要考虑去维
护他，⽽且使⽤的过程中是不是要考虑各种问题，⽐如消息重复消费、消息丢失、消息的顺序消费等
等，反正⽤了之后就是贼烦。

数据一致性

​	这个其实是分布式服务本身就存在的⼀个问题，不仅仅是消息队列的问题，但是⽤了
消息队列这个问题会暴露得⽐较严重⼀点。	

可⽤性
	你搞个系统本身没啥问题，你现在突然接⼊⼀个中间件在那放着，万⼀挂了怎么办？我下个单MQ挂
了，优惠券不扣了，积分不减了，这不是杀⼀个程序员能搞定的吧，感觉得杀⼀⽚。

## 消息处理（重复消费和顺序消费）

重复消费

​	接口幂等性。

​	⼀般幂等，我会分场景去考虑，看是强校验还是弱校验，⽐如跟⾦钱相关的场景那就
很关键呀，就做强校验，别不是很重要的场景做弱校验。

顺序消费

​	  无序消息：无序消息也指普通的消息，Producer 只管发送消息，Consumer 只管接收消息，至于消息和消息之间的顺序并没有保证。举例 Producer 依次发送 orderId 为 1、2、3 的消息，Consumer 接到的消息顺序有可能是 1、2、3，也有可能是 2、1、3等情况，这就是普通消息。 

​	  全局顺序：对于指定的一个 Topic，所有消息按照严格的先入先出（FIFO）的顺序进行发布和消费。举例 比如 Producer 发送orderId 1,3,2 的消息, 那么 Consumer 也必须要按照 1,3,2 的顺序进行消费。  

​	实现原理：

  	我们知道 生产的message最终会存放在Queue中，如果一个Topic关联了16个Queue,如果我们不指定消息往哪个队列里放，那么默认是平均分配消息到16个queue，好比有100条消息，那么这100条消息会平均分配在这16个Queue上，那么每个Queue大概放5～6个左右。这里有一点很重的是:同一个queue，存储在里面的message 是按照先进先出的原则这个时候思路就来了，好比有orderId=1的3条消息，分别是 订单生产、订单付款、订单完成。**只要保证它们放到同一个Queue那就保证消费者先进先出了。这就保证局部顺序了**，即同一订单按照先后顺序放到同一Queue,那么取消息的时候就可以保证先进先取出。至于**全局顺序**，你把所有消息都放在一个Queue里,自然就保证全局消息了。**但是**，  这里还有很关键的一点，好比在一个消费者集群的情况下，消费者1先去Queue拿消息，它拿到了 订单生成，它拿完后，消费者2去queue拿到的是订单支付。拿的顺序是没毛病了，但关键是先拿到不代表先消费完它。会存在虽然你消费者1先拿到订单生成，但由于网络等原因，消费者2比你真正的先消费消息。这是不是很尴尬了。订单付款还是可能会比订单生成更早消费的情况。那怎么办。**分布式锁来了！！**Rocker采用的是分段锁，它不是锁整个Broker而是锁里面的单个Queue，因为只要锁单个Queue就可以保证局部顺序消费了。所以最终的消费者这边的逻辑就是消费者1去Queue拿 订单生成，它就锁住了整个Queue，只有它消费完成并返回成功后，这个锁才会释放。然后下一个消费者去拿到 订单支付 同样锁住当前Queue,这样的一个过程来真正保证对同一个Queue能够真正意义上的顺序消费，而不仅仅是顺序取出。

​	相比较普通消息的消费，顺序消费在向broker发送消息的时候要指定**MessageQueueSelector**  ，以确保都发送到同一个queue中。

​	总结：

​	如果要发送顺序消息，首先，需要保证顺序的消息要发送到同一个messagequeue中；其次，一个messagequeue只能被一个消费者消费，这点是由消息队列的分配机制来保证的；最后，一个消费者内部对一个mq的消费要保证是有序的（消费有序要么就一个消费者，要么就队列加锁）。 我们要做到生产者 - messagequeue - 消费者之间是一对一对一的关系。

## 选型

我们主要调研了几个主流的mq，kafka、rabbitmq、rocketmq、activemq，选型我们主要基于以下几个点去考虑：

1. 由于我们系统的qps压力比较大，所以性能是首要考虑的要素。
2. 开发语言，由于我们的开发语言是java，主要是为了方便二次开发。
3. 对于高并发的业务场景是必须的，所以需要支持分布式架构的设计。
4. 功能全面，由于不同的业务场景，可能会用到顺序消息、事务消息等。

基于以上几个考虑，我们最终选择了RocketMQ。

![img](https://pic2.zhimg.com/80/v2-2e5171ae4134df45d713dcf64c556555_720w.jpg)

## **说了这么多，那你说说RocketMQ实现原理吧？**

RocketMQ由NameServer注册中心集群、Producer生产者集群、Consumer消费者集群和若干Broker（RocketMQ进程）组成，它的架构原理是这样的：

1. Broker在启动的时候去向所有的NameServer注册，并保持长连接，每30s发送一次心跳
2. Producer在发送消息的时候从NameServer获取Broker服务器地址，根据负载均衡算法选择一台服务器来发送消息
3. Conusmer消费消息的时候同样从NameServer获取Broker地址，然后主动拉取消息来消费

![img](https://pic3.zhimg.com/80/v2-c0e49ca7f6357fba4ee00af2d53c63f2_720w.jpg)

## **为什么RocketMQ不使用Zookeeper作为注册中心呢？**

我认为有以下几个点是不使用zookeeper的原因：

1. 根据CAP理论，同时最多只能满足两个点，而zookeeper满足的是CP，也就是说zookeeper并不能保证服务的可用性，zookeeper在进行选举的时候，整个选举的时间太长，期间整个集群都处于不可用的状态，而这对于一个注册中心来说肯定是不能接受的，作为服务发现来说就应该是为可用性而设计。
2. 基于性能的考虑，NameServer本身的实现非常轻量，而且可以通过增加机器的方式水平扩展，增加集群的抗压能力，而zookeeper的写是不可扩展的，而zookeeper要解决这个问题只能通过划分领域，划分多个zookeeper集群来解决，首先操作起来太复杂，其次这样还是又违反了CAP中的A的设计，导致服务之间是不连通的。
3. 持久化的机制来带的问题，ZooKeeper 的 ZAB 协议对每一个写请求，会在每个 ZooKeeper 节点上保持写一个**事务日志**，同时再加上定期的将内存数据镜像（Snapshot）到磁盘来保证数据的一致性和持久性，而对于一个简单的服务发现的场景来说，这其实没有太大的必要，这个实现方案太重了。而且本身存储的数据应该是高度定制化的。
4. 消息发送应该弱依赖注册中心，而RocketMQ的设计理念也正是基于此，生产者在第一次发送消息的时候从NameServer获取到Broker地址后缓存到本地，如果NameServer整个集群不可用，短时间内对于生产者和消费者并不会产生太大影响。(**服务调用（请求响应流）链路应该是弱依赖注册中心，必须仅在服务发布，机器上下线，服务扩缩容等必要时才依赖注册中心。**)

## **那Broker是怎么保存数据的呢？**

RocketMQ主要的存储文件包括commitlog文件、consumequeue文件、indexfile文件。

Broker在收到消息之后，会把消息保存到commitlog的文件当中，而同时在分布式的存储当中，每个broker都会保存一部分topic的数据，同时，每个topic对应的messagequeue下都会生成consumequeue文件用于保存commitlog的物理位置偏移量offset，indexfile中会保存key和offset的对应关系。

![img](https://pic4.zhimg.com/80/v2-c14e6fd1ec5edda32d84c81bc30777f3_720w.jpg)

CommitLog文件保存于${Rocket_Home}/store/commitlog目录中，从图中我们可以明显看出来文件名的偏移量，每个文件默认1G，写满后自动生成一个新的文件。

![img](https://pic1.zhimg.com/80/v2-6a9a48925df77d9d0e13af0bf09a7f04_720w.jpeg)

由于同一个topic的消息并不是连续的存储在commitlog中，消费者如果直接从commitlog获取消息效率非常低，所以通过consumequeue保存commitlog中消息的偏移量的物理地址，这样消费者在消费的时候先从consumequeue中根据偏移量定位到具体的commitlog物理文件，然后根据一定的规则（offset和文件大小取模）在commitlog中快速定位。

![img](https://pic1.zhimg.com/80/v2-ae44a8167e20472537f5911b30d6167c_720w.jpg)

## **Master和Slave之间是怎么同步数据的呢？**

而消息在master和slave之间的同步是根据**raft协议**来进行的：

1. 在broker收到消息后，会被标记为uncommitted状态
2. 然后会把消息发送给所有的slave
3. slave在收到消息之后返回ack响应给master
4. master在收到超过半数的ack之后，把消息标记为committed
5. 发送committed消息给所有slave，slave也修改状态为committed

## **你知道RocketMQ为什么速度快吗？**

是因为使用了顺序存储、Page Cache和异步刷盘。

1. 我们在写入commitlog的时候是顺序写入的，这样比随机写入的性能就会提高很多
2. 写入commitlog的时候并不是直接写入磁盘，而是先写入操作系统的PageCache
3. 最后由操作系统异步将缓存中的数据刷到磁盘

## **什么是事务、半事务消息？怎么实现的？**

事务消息就是MQ提供的类似XA的分布式事务能力，通过事务消息可以达到分布式事务的最终一致性。

半事务消息就是MQ收到了生产者的消息，但是没有收到二次确认，不能投递的消息。

实现原理如下：

1. 生产者先发送一条半事务消息到MQ
2. MQ收到消息后返回ack确认
3. 生产者开始执行本地事务
4. 如果事务执行成功发送commit到MQ，失败发送rollback
5. 如果MQ长时间未收到生产者的二次确认commit或者rollback，MQ对生产者发起消息回查
6. 生产者查询事务执行最终状态
7. 根据查询事务状态再次提交二次确认

最终，如果MQ收到二次确认commit，就可以把消息投递给消费者，反之如果是rollback，消息会保存下来并且在3天后被删除。

![img](https://pic1.zhimg.com/80/v2-8eb0341a70a92125700b32b93ea27b90_720w.jpg)